{"log":"OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\n","stream":"stderr","time":"2021-03-11T10:32:09.7665657Z"}
{"log":"WARNING: An illegal reflective access operation has occurred\n","stream":"stderr","time":"2021-03-11T10:32:11.5973066Z"}
{"log":"WARNING: Illegal reflective access by com.headius.backport9.modules.Modules (file:/usr/share/logstash/logstash-core/lib/jars/jruby-complete-9.2.7.0.jar) to field java.io.FileDescriptor.fd\n","stream":"stderr","time":"2021-03-11T10:32:11.59734Z"}
{"log":"WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.Modules\n","stream":"stderr","time":"2021-03-11T10:32:11.5973432Z"}
{"log":"WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","stream":"stderr","time":"2021-03-11T10:32:11.5973457Z"}
{"log":"WARNING: All illegal access operations will be denied in a future release\n","stream":"stderr","time":"2021-03-11T10:32:11.597348Z"}
{"log":"Thread.exclusive is deprecated, use Thread::Mutex\n","stream":"stderr","time":"2021-03-11T10:32:26.6263028Z"}
{"log":"Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties\n","stream":"stdout","time":"2021-03-11T10:32:30.3336591Z"}
{"log":"[2021-03-11T10:32:30,494][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=\u003e\"path.queue\", :path=\u003e\"/usr/share/logstash/data/queue\"}\n","stream":"stdout","time":"2021-03-11T10:32:30.4964226Z"}
{"log":"[2021-03-11T10:32:30,507][INFO ][logstash.setting.writabledirectory] Creating directory {:setting=\u003e\"path.dead_letter_queue\", :path=\u003e\"/usr/share/logstash/data/dead_letter_queue\"}\n","stream":"stdout","time":"2021-03-11T10:32:30.5078831Z"}
{"log":"[2021-03-11T10:32:30,792][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=\u003e\"7.3.2\"}\n","stream":"stdout","time":"2021-03-11T10:32:30.7927613Z"}
{"log":"[2021-03-11T10:32:30,811][INFO ][logstash.agent           ] No persistent UUID file found. Generating new UUID {:uuid=\u003e\"0220f094-3e3b-4d27-b011-c74674eec2ea\", :path=\u003e\"/usr/share/logstash/data/uuid\"}\n","stream":"stdout","time":"2021-03-11T10:32:30.8121897Z"}
{"log":"[2021-03-11T10:32:31,208][WARN ][logstash.monitoringextension.pipelineregisterhook] xpack.monitoring.enabled has not been defined, but found elasticsearch configuration. Please explicitly set `xpack.monitoring.enabled: true` in logstash.yml\n","stream":"stdout","time":"2021-03-11T10:32:31.2092384Z"}
{"log":"[2021-03-11T10:32:32,039][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T10:32:32.0403329Z"}
{"log":"[2021-03-11T10:32:32,227][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T10:32:32.2276354Z"}
{"log":"[2021-03-11T10:32:32,286][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T10:32:32.2864955Z"}
{"log":"[2021-03-11T10:32:32,288][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T10:32:32.2886324Z"}
{"log":"[2021-03-11T10:32:32,411][INFO ][logstash.monitoring.internalpipelinesource] Monitoring License OK\n","stream":"stdout","time":"2021-03-11T10:32:32.4115939Z"}
{"log":"[2021-03-11T10:32:32,412][INFO ][logstash.monitoring.internalpipelinesource] Validated license for monitoring. Enabling monitoring pipeline.\n","stream":"stdout","time":"2021-03-11T10:32:32.4126258Z"}
{"log":"[2021-03-11T10:32:33,104][INFO ][org.reflections.Reflections] Reflections took 31 ms to scan 1 urls, producing 19 keys and 39 values \n","stream":"stdout","time":"2021-03-11T10:32:33.1048368Z"}
{"log":"[2021-03-11T10:32:34,153][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://172.20.0.3:9200/]}}\n","stream":"stdout","time":"2021-03-11T10:32:34.1545783Z"}
{"log":"[2021-03-11T10:32:34,164][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://172.20.0.3:9200/\"}\n","stream":"stdout","time":"2021-03-11T10:32:34.1645185Z"}
{"log":"[2021-03-11T10:32:34,171][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T10:32:34.1720104Z"}
{"log":"[2021-03-11T10:32:34,171][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T10:32:34.1722334Z"}
{"log":"[2021-03-11T10:32:34,181][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"//172.20.0.3:9200\"]}\n","stream":"stdout","time":"2021-03-11T10:32:34.1819963Z"}
{"log":"[2021-03-11T10:32:34,214][INFO ][logstash.outputs.elasticsearch] Using default mapping template\n","stream":"stdout","time":"2021-03-11T10:32:34.2151025Z"}
{"log":"[2021-03-11T10:32:34,249][WARN ][org.logstash.instrument.metrics.gauge.LazyDelegatingGauge] A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been create for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.\n","stream":"stdout","time":"2021-03-11T10:32:34.2499824Z"}
{"log":"[2021-03-11T10:32:34,253][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e16, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2000, :thread=\u003e\"#\u003cThread:0x51a6b25f run\u003e\"}\n","stream":"stdout","time":"2021-03-11T10:32:34.2537483Z"}
{"log":"[2021-03-11T10:32:34,256][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=\u003e{\"index_patterns\"=\u003e\"logstash-*\", \"version\"=\u003e60001, \"settings\"=\u003e{\"index.refresh_interval\"=\u003e\"5s\", \"number_of_shards\"=\u003e1}, \"mappings\"=\u003e{\"dynamic_templates\"=\u003e[{\"message_field\"=\u003e{\"path_match\"=\u003e\"message\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse}}}, {\"string_fields\"=\u003e{\"match\"=\u003e\"*\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse, \"fields\"=\u003e{\"keyword\"=\u003e{\"type\"=\u003e\"keyword\", \"ignore_above\"=\u003e256}}}}}], \"properties\"=\u003e{\"@timestamp\"=\u003e{\"type\"=\u003e\"date\"}, \"@version\"=\u003e{\"type\"=\u003e\"keyword\"}, \"geoip\"=\u003e{\"dynamic\"=\u003etrue, \"properties\"=\u003e{\"ip\"=\u003e{\"type\"=\u003e\"ip\"}, \"location\"=\u003e{\"type\"=\u003e\"geo_point\"}, \"latitude\"=\u003e{\"type\"=\u003e\"half_float\"}, \"longitude\"=\u003e{\"type\"=\u003e\"half_float\"}}}}}}}\n","stream":"stdout","time":"2021-03-11T10:32:34.2586815Z"}
{"log":"[2021-03-11T10:32:34,512][INFO ][logstash.inputs.file     ] No sincedb_path set, generating one based on the \"path\" setting {:sincedb_path=\u003e\"/usr/share/logstash/data/plugins/inputs/file/.sincedb_b7a3bb4495f9939e1fe659452575c1f2\", :path=\u003e[\"/home/logs/testLogJson.json\"]}\n","stream":"stdout","time":"2021-03-11T10:32:34.5133612Z"}
{"log":"[2021-03-11T10:32:34,533][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T10:32:34.534196Z"}
{"log":"[2021-03-11T10:32:34,567][INFO ][filewatch.observingtail  ] START, creating Discoverer, Watch with file and sincedb collections\n","stream":"stdout","time":"2021-03-11T10:32:34.5683562Z"}
{"log":"[2021-03-11T10:32:34,577][INFO ][logstash.agent           ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T10:32:34.5781328Z"}
{"log":"[2021-03-11T10:32:35,114][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting \"document_type\" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=\u003e\"document_type\", :plugin=\u003e\u003cLogStash::Outputs::ElasticSearch bulk_path=\u003e\"/_monitoring/bulk?system_id=logstash\u0026system_api_version=7\u0026interval=1s\", hosts=\u003e[http://elasticsearch:9200], sniffing=\u003efalse, manage_template=\u003efalse, id=\u003e\"7d7dfa0f023f65240aeb31ebb353da5a42dc782979a2bd7e26e28b7cbd509bb3\", document_type=\u003e\"%{[@metadata][document_type]}\", enable_metric=\u003etrue, codec=\u003e\u003cLogStash::Codecs::Plain id=\u003e\"plain_e3756c33-a230-4421-b252-bc0fbe9c9fc5\", enable_metric=\u003etrue, charset=\u003e\"UTF-8\"\u003e, workers=\u003e1, template_name=\u003e\"logstash\", template_overwrite=\u003efalse, doc_as_upsert=\u003efalse, script_type=\u003e\"inline\", script_lang=\u003e\"painless\", script_var_name=\u003e\"event\", scripted_upsert=\u003efalse, retry_initial_interval=\u003e2, retry_max_interval=\u003e64, retry_on_conflict=\u003e1, ilm_enabled=\u003e\"auto\", ilm_rollover_alias=\u003e\"logstash\", ilm_pattern=\u003e\"{now/d}-000001\", ilm_policy=\u003e\"logstash-policy\", action=\u003e\"index\", ssl_certificate_verification=\u003etrue, sniffing_delay=\u003e5, timeout=\u003e60, pool_max=\u003e1000, pool_max_per_route=\u003e100, resurrect_delay=\u003e5, validate_after_inactivity=\u003e10000, http_compression=\u003efalse\u003e}\n","stream":"stdout","time":"2021-03-11T10:32:35.1188748Z"}
{"log":"[2021-03-11T10:32:35,152][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T10:32:35.1535215Z"}
{"log":"[2021-03-11T10:32:35,160][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T10:32:35.1606612Z"}
{"log":"[2021-03-11T10:32:35,170][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T10:32:35.1712429Z"}
{"log":"[2021-03-11T10:32:35,171][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T10:32:35.1717658Z"}
{"log":"[2021-03-11T10:32:35,174][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"http://elasticsearch:9200\"]}\n","stream":"stdout","time":"2021-03-11T10:32:35.1746488Z"}
{"log":"[2021-03-11T10:32:35,187][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\".monitoring-logstash\", \"pipeline.workers\"=\u003e1, \"pipeline.batch.size\"=\u003e2, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2, :thread=\u003e\"#\u003cThread:0x58d08fbf run\u003e\"}\n","stream":"stdout","time":"2021-03-11T10:32:35.1891709Z"}
{"log":"[2021-03-11T10:32:35,231][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T10:32:35.2324069Z"}
{"log":"[2021-03-11T10:32:35,249][INFO ][logstash.agent           ] Pipelines running {:count=\u003e2, :running_pipelines=\u003e[:\".monitoring-logstash\", :main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T10:32:35.2500703Z"}
{"log":"[2021-03-11T10:32:35,527][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=\u003e9600}\n","stream":"stdout","time":"2021-03-11T10:32:35.5281537Z"}
{"log":"{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.209Z\",\"time\":\"2021-03-10T16:14:59.5364712Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:14:59.535 INFO {_internal} [_log]  * Running on http://172.20.0.6:80/ (Press CTRL+C to quit)\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.289Z\",\"time\":\"2021-03-10T16:15:53.2775489Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:53.276 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:53] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.292Z\",\"time\":\"2021-03-10T16:15:54.0800512Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:54.079 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:54] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.293Z\",\"time\":\"2021-03-10T16:15:54.9700089Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:54.969 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:54] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.294Z\",\"time\":\"2021-03-10T16:15:55.1490353Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:55.148 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:55] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.296Z\",\"time\":\"2021-03-10T16:15:55.2744959Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:55.274 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:55] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.297Z\",\"time\":\"2021-03-10T16:15:55.4198383Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:55.419 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:55] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.298Z\",\"time\":\"2021-03-10T16:15:55.67074Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:55.669 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:55] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.300Z\",\"time\":\"2021-03-10T16:15:55.8327494Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:55.832 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:55] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.301Z\",\"time\":\"2021-03-10T16:15:55.9887691Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:55.988 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:55] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.303Z\",\"time\":\"2021-03-10T16:15:56.1521754Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:56.151 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:56] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.304Z\",\"time\":\"2021-03-10T16:15:56.2632926Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:56.262 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:56] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.305Z\",\"time\":\"2021-03-10T16:15:56.4242024Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:56.423 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:56] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.306Z\",\"time\":\"2021-03-10T16:15:56.568658Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:15:56.568 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:15:56] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.307Z\",\"time\":\"2021-03-10T16:16:08.354136Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:08.353 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:08] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.308Z\",\"time\":\"2021-03-10T16:16:09.5629538Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:09.562 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:09] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.309Z\",\"time\":\"2021-03-10T16:16:09.7232284Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:09.722 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:09] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.311Z\",\"time\":\"2021-03-10T16:16:09.8827652Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:09.882 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:09] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.312Z\",\"time\":\"2021-03-10T16:16:10.0109041Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:10.010 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:10] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.313Z\",\"time\":\"2021-03-10T16:16:10.1614749Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:10.161 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:10] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.315Z\",\"time\":\"2021-03-10T16:16:10.3041707Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:10.303 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:10] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.315Z\",\"time\":\"2021-03-10T16:16:10.4396465Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:10.439 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:10] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.317Z\",\"time\":\"2021-03-10T16:16:10.6097532Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:10.609 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:10] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.318Z\",\"time\":\"2021-03-10T16:16:10.7371675Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:10.736 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:10] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.319Z\",\"time\":\"2021-03-10T16:16:22.0678224Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:22.067 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.320Z\",\"time\":\"2021-03-10T16:16:22.227841Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:22.227 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.339Z\",\"time\":\"2021-03-10T16:16:22.3884516Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T16:16:22.387 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.340Z\",\"time\":\"2021-03-10T17:16:22.5283995Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T17:16:22.527 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.341Z\",\"time\":\"2021-03-10T17:16:22.7889393Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T17:16:22.788 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T10:32:35.343Z\",\"time\":\"2021-03-10T17:16:22.9572624Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-10T17:16:22.956 INFO {_internal} [_log] 172.20.0.1 - - [10/Mar/2021 16:16:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.466Z\",\"time\":\"2021-03-11T16:38:11.2767447Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:38:11.276 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:38:11] \\\"GET / HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.466Z\",\"time\":\"2021-03-11T16:37:45.4151197Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:45.414 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:45] \\\"GET /TEST/defaultModel?test=%7B%0A%20%20%22id%22%3A%201%2C%0A%20%20%22type%22%3A%20%22test%22%2C%0A%20%20%22color%22%3A%20%22blue%22%0A%7D HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.467Z\",\"time\":\"2021-03-11T16:38:12.5932462Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:38:12.592 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:38:12] \\\"GET / HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.465Z\",\"time\":\"2021-03-11T16:37:30.0361759Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:30.035 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:30] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.463Z\",\"time\":\"2021-03-11T16:37:19.4378873Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:19.437 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:19] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.464Z\",\"time\":\"2021-03-11T16:37:22.2230234Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:22.222 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:22] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.463Z\",\"time\":\"2021-03-11T10:32:09.3288646Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T10:32:09.328 INFO {_internal} [_log]  * Running on http://172.20.0.6:80/ (Press CTRL+C to quit)\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.466Z\",\"time\":\"2021-03-11T16:38:07.3410256Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:38:07.340 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:38:07] \\\"GET / HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.466Z\",\"time\":\"2021-03-11T16:37:46.7130125Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:46.712 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:46] \\\"GET /TEST/defaultModel?test=%7B%0A%20%20%22id%22%3A%201%2C%0A%20%20%22type%22%3A%20%22test%22%2C%0A%20%20%22color%22%3A%20%22blue%22%0A%7D HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.464Z\",\"time\":\"2021-03-11T16:37:23.4980986Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:23.497 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:23] \\\"GET /health HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.465Z\",\"time\":\"2021-03-11T16:37:42.8733839Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:42.873 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:42] \\\"GET /TEST/defaultModel?test=%7B%0A%20%20%22id%22%3A%201%2C%0A%20%20%22type%22%3A%20%22test%22%2C%0A%20%20%22color%22%3A%20%22blue%22%0A%7D HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.465Z\",\"time\":\"2021-03-11T16:37:28.8778008Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:28.877 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:28] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:43:49.464Z\",\"time\":\"2021-03-11T16:37:27.8921132Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:37:27.891 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:37:27] \\\"GET /environment HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.746Z\",\"time\":\"2021-03-11T16:46:24.8006313Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:24.800 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:24] \\\"POST /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.747Z\",\"time\":\"2021-03-11T16:46:26.2616881Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:26.261 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:26] \\\"POST /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.748Z\",\"time\":\"2021-03-11T16:46:27.7825739Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:27.782 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:27] \\\"POST /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.746Z\",\"time\":\"2021-03-11T16:46:06.6806589Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:06.680 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:06] \\\"POST /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.747Z\",\"time\":\"2021-03-11T16:46:26.2612121Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:26.260 INFO {main} [TEST] {'Data1': 'A String for Data 1', 'Data2': 'A String for Data 2', 'Data3': 'A String for Data 3', 'model': 'defaultModel'}\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.746Z\",\"time\":\"2021-03-11T16:46:24.8000567Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:24.799 INFO {main} [TEST] {'Data1': 'A String for Data 1', 'Data2': 'A String for Data 2', 'Data3': 'A String for Data 3', 'model': 'defaultModel'}\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.744Z\",\"time\":\"2021-03-11T16:46:06.6750342Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:06.674 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:06] \\\"OPTIONS /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.746Z\",\"time\":\"2021-03-11T16:46:24.7947799Z\",\"path\":\"/h","stream":"stdout","time":"2021-03-11T16:47:47.8734146Z"}
{"log":"ome/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:24.794 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:24] \\\"OPTIONS /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.745Z\",\"time\":\"2021-03-11T16:46:06.6800648Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:06.679 INFO {main} [TEST] {'Data1': 'A String for Data 1', 'Data2': 'A String for Data 2', 'Data3': 'A String for Data 3', 'model': 'defaultModel'}\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.748Z\",\"time\":\"2021-03-11T16:46:37.6229515Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:37.622 INFO {main} [TEST] {'Data1': 'A String for Data 1', 'Data2': 'A String for Data 2', 'Data3': 'A String for Data 3', 'model': 'defaultModel'}\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.748Z\",\"time\":\"2021-03-11T16:46:37.6181342Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:37.617 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:37] \\\"OPTIONS /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.747Z\",\"time\":\"2021-03-11T16:46:27.7815197Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:27.780 INFO {main} [TEST] {'Data1': 'A String for Data 1', 'Data2': 'A String for Data 2', 'Data3': 'A String for Data 3', 'model': 'defaultModel'}\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.749Z\",\"time\":\"2021-03-11T16:46:50.5091817Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:50.508 INFO {main} [TEST] {'Data1': 'A String for Data 1', 'Data2': 'A String for Data 2', 'Data3': 'A String for Data 3', 'model': 'defaultModel'}\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.748Z\",\"time\":\"2021-03-11T16:46:37.6235688Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:37.623 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:37] \\\"POST /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.748Z\",\"time\":\"2021-03-11T16:46:44.789251Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:44.788 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:44] \\\"OPTIONS /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}{\"@version\":\"1\",\"stream\":\"stdout\",\"@timestamp\":\"2021-03-11T16:47:47.749Z\",\"time\":\"2021-03-11T16:46:50.5101863Z\",\"path\":\"/home/logs/testLogJson.json\",\"log\":\"2021-03-11T16:46:50.509 INFO {_internal} [_log] 172.20.0.1 - - [11/Mar/2021 16:46:50] \\\"POST /TEST/defaultModel HTTP/1.1\\\" 200 -\\r\\n\",\"host\":\"d98ed3887bd8\",\"type\":\"json\"}[2021-03-11T16:47:59,616][WARN ][logstash.runner          ] SIGTERM received. Shutting down.\n","stream":"stdout","time":"2021-03-11T16:47:47.8734146Z"}
{"log":"[2021-03-11T16:47:59,686][INFO ][filewatch.observingtail  ] QUIT - closing all files and shutting down.\n","stream":"stdout","time":"2021-03-11T16:47:59.686816Z"}
{"log":"[2021-03-11T16:47:59,871][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:47:59.8722772Z"}
{"log":"[2021-03-11T16:48:00,161][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:48:00.1618972Z"}
{"log":"[2021-03-11T16:48:00,764][INFO ][logstash.runner          ] Logstash shut down.\n","stream":"stdout","time":"2021-03-11T16:48:00.7652032Z"}
{"log":"OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\n","stream":"stderr","time":"2021-03-11T16:48:01.5066414Z"}
{"log":"WARNING: An illegal reflective access operation has occurred\n","stream":"stderr","time":"2021-03-11T16:48:02.7728341Z"}
{"log":"WARNING: Illegal reflective access by com.headius.backport9.modules.Modules (file:/usr/share/logstash/logstash-core/lib/jars/jruby-complete-9.2.7.0.jar) to field java.io.FileDescriptor.fd\n","stream":"stderr","time":"2021-03-11T16:48:02.7728716Z"}
{"log":"WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.Modules\n","stream":"stderr","time":"2021-03-11T16:48:02.7728752Z"}
{"log":"WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","stream":"stderr","time":"2021-03-11T16:48:02.7728781Z"}
{"log":"WARNING: All illegal access operations will be denied in a future release\n","stream":"stderr","time":"2021-03-11T16:48:02.7728803Z"}
{"log":"Thread.exclusive is deprecated, use Thread::Mutex\n","stream":"stderr","time":"2021-03-11T16:48:13.2860327Z"}
{"log":"Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties\n","stream":"stdout","time":"2021-03-11T16:48:15.6624509Z"}
{"log":"[2021-03-11T16:48:16,042][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=\u003e\"7.3.2\"}\n","stream":"stdout","time":"2021-03-11T16:48:16.0442767Z"}
{"log":"[2021-03-11T16:48:16,442][WARN ][logstash.monitoringextension.pipelineregisterhook] xpack.monitoring.enabled has not been defined, but found elasticsearch configuration. Please explicitly set `xpack.monitoring.enabled: true` in logstash.yml\n","stream":"stdout","time":"2021-03-11T16:48:16.4430032Z"}
{"log":"[2021-03-11T16:48:17,029][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:48:17.0307688Z"}
{"log":"[2021-03-11T16:48:17,197][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:48:17.1981622Z"}
{"log":"[2021-03-11T16:48:17,242][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:48:17.2431187Z"}
{"log":"[2021-03-11T16:48:17,244][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:48:17.2452442Z"}
{"log":"[2021-03-11T16:48:17,334][INFO ][logstash.monitoring.internalpipelinesource] Monitoring License OK\n","stream":"stdout","time":"2021-03-11T16:48:17.3346147Z"}
{"log":"[2021-03-11T16:48:17,335][INFO ][logstash.monitoring.internalpipelinesource] Validated license for monitoring. Enabling monitoring pipeline.\n","stream":"stdout","time":"2021-03-11T16:48:17.3358977Z"}
{"log":"[2021-03-11T16:48:18,033][INFO ][org.reflections.Reflections] Reflections took 30 ms to scan 1 urls, producing 19 keys and 39 values \n","stream":"stdout","time":"2021-03-11T16:48:18.0344442Z"}
{"log":"[2021-03-11T16:48:19,053][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://172.20.0.3:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:48:19.0540687Z"}
{"log":"[2021-03-11T16:48:19,061][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://172.20.0.3:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:48:19.0621277Z"}
{"log":"[2021-03-11T16:48:19,066][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:48:19.0666109Z"}
{"log":"[2021-03-11T16:48:19,066][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:48:19.0669784Z"}
{"log":"[2021-03-11T16:48:19,074][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"//172.20.0.3:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:48:19.0751742Z"}
{"log":"[2021-03-11T16:48:19,104][INFO ][logstash.outputs.elasticsearch] Using default mapping template\n","stream":"stdout","time":"2021-03-11T16:48:19.1050266Z"}
{"log":"[2021-03-11T16:48:19,140][WARN ][org.logstash.instrument.metrics.gauge.LazyDelegatingGauge] A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been create for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.\n","stream":"stdout","time":"2021-03-11T16:48:19.1408879Z"}
{"log":"[2021-03-11T16:48:19,140][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=\u003e{\"index_patterns\"=\u003e\"logstash-*\", \"version\"=\u003e60001, \"settings\"=\u003e{\"index.refresh_interval\"=\u003e\"5s\", \"number_of_shards\"=\u003e1}, \"mappings\"=\u003e{\"dynamic_templates\"=\u003e[{\"message_field\"=\u003e{\"path_match\"=\u003e\"message\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse}}}, {\"string_fields\"=\u003e{\"match\"=\u003e\"*\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse, \"fields\"=\u003e{\"keyword\"=\u003e{\"type\"=\u003e\"keyword\", \"ignore_above\"=\u003e256}}}}}], \"properties\"=\u003e{\"@timestamp\"=\u003e{\"type\"=\u003e\"date\"}, \"@version\"=\u003e{\"type\"=\u003e\"keyword\"}, \"geoip\"=\u003e{\"dynamic\"=\u003etrue, \"properties\"=\u003e{\"ip\"=\u003e{\"type\"=\u003e\"ip\"}, \"location\"=\u003e{\"type\"=\u003e\"geo_point\"}, \"latitude\"=\u003e{\"type\"=\u003e\"half_float\"}, \"longitude\"=\u003e{\"type\"=\u003e\"half_float\"}}}}}}}\n","stream":"stdout","time":"2021-03-11T16:48:19.1413725Z"}
{"log":"[2021-03-11T16:48:19,144][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e16, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2000, :thread=\u003e\"#\u003cThread:0x2895237 run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:48:19.1446879Z"}
{"log":"[2021-03-11T16:48:19,387][INFO ][logstash.inputs.file     ] No sincedb_path set, generating one based on the \"path\" setting {:sincedb_path=\u003e\"/usr/share/logstash/data/plugins/inputs/file/.sincedb_b7a3bb4495f9939e1fe659452575c1f2\", :path=\u003e[\"/home/logs/testLogJson.json\"]}\n","stream":"stdout","time":"2021-03-11T16:48:19.3877305Z"}
{"log":"[2021-03-11T16:48:19,409][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:48:19.4097728Z"}
{"log":"[2021-03-11T16:48:19,447][INFO ][filewatch.observingtail  ] START, creating Discoverer, Watch with file and sincedb collections\n","stream":"stdout","time":"2021-03-11T16:48:19.4476656Z"}
{"log":"[2021-03-11T16:48:19,459][INFO ][logstash.agent           ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:48:19.4601238Z"}
{"log":"[2021-03-11T16:48:19,825][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting \"document_type\" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=\u003e\"document_type\", :plugin=\u003e\u003cLogStash::Outputs::ElasticSearch bulk_path=\u003e\"/_monitoring/bulk?system_id=logstash\u0026system_api_version=7\u0026interval=1s\", hosts=\u003e[http://elasticsearch:9200], sniffing=\u003efalse, manage_template=\u003efalse, id=\u003e\"7d7dfa0f023f65240aeb31ebb353da5a42dc782979a2bd7e26e28b7cbd509bb3\", document_type=\u003e\"%{[@metadata][document_type]}\", enable_metric=\u003etrue, codec=\u003e\u003cLogStash::Codecs::Plain id=\u003e\"plain_39c72dd7-21fd-4ffa-b746-01319d526e51\", enable_metric=\u003etrue, charset=\u003e\"UTF-8\"\u003e, workers=\u003e1, template_name=\u003e\"logstash\", template_overwrite=\u003efalse, doc_as_upsert=\u003efalse, script_type=\u003e\"inline\", script_lang=\u003e\"painless\", script_var_name=\u003e\"event\", scripted_upsert=\u003efalse, retry_initial_interval=\u003e2, retry_max_interval=\u003e64, retry_on_conflict=\u003e1, ilm_enabled=\u003e\"auto\", ilm_rollover_alias=\u003e\"logstash\", ilm_pattern=\u003e\"{now/d}-000001\", ilm_policy=\u003e\"logstash-policy\", action=\u003e\"index\", ssl_certificate_verification=\u003etrue, sniffing_delay=\u003e5, timeout=\u003e60, pool_max=\u003e1000, pool_max_per_route=\u003e100, resurrect_delay=\u003e5, validate_after_inactivity=\u003e10000, http_compression=\u003efalse\u003e}\n","stream":"stdout","time":"2021-03-11T16:48:19.8289013Z"}
{"log":"[2021-03-11T16:48:19,857][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:48:19.8579962Z"}
{"log":"[2021-03-11T16:48:19,863][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:48:19.8640139Z"}
{"log":"[2021-03-11T16:48:19,868][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:48:19.8694037Z"}
{"log":"[2021-03-11T16:48:19,869][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:48:19.8699292Z"}
{"log":"[2021-03-11T16:48:19,871][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"http://elasticsearch:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:48:19.872025Z"}
{"log":"[2021-03-11T16:48:19,876][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\".monitoring-logstash\", \"pipeline.workers\"=\u003e1, \"pipeline.batch.size\"=\u003e2, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2, :thread=\u003e\"#\u003cThread:0x54f05b86 run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:48:19.8770057Z"}
{"log":"[2021-03-11T16:48:19,892][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:48:19.893229Z"}
{"log":"[2021-03-11T16:48:19,908][INFO ][logstash.agent           ] Pipelines running {:count=\u003e2, :running_pipelines=\u003e[:\".monitoring-logstash\", :main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:48:19.9092869Z"}
{"log":"[2021-03-11T16:48:20,147][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=\u003e9600}\n","stream":"stdout","time":"2021-03-11T16:48:20.1484802Z"}
{"log":"[2021-03-11T16:50:06,575][WARN ][logstash.runner          ] SIGTERM received. Shutting down.\n","stream":"stdout","time":"2021-03-11T16:50:06.5755441Z"}
{"log":"[2021-03-11T16:50:06,632][INFO ][filewatch.observingtail  ] QUIT - closing all files and shutting down.\n","stream":"stdout","time":"2021-03-11T16:50:06.6331534Z"}
{"log":"[2021-03-11T16:50:07,063][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:50:07.0643256Z"}
{"log":"[2021-03-11T16:50:07,063][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:50:07.0643597Z"}
{"log":"[2021-03-11T16:50:07,951][INFO ][logstash.runner          ] Logstash shut down.\n","stream":"stdout","time":"2021-03-11T16:50:07.9515308Z"}
{"log":"OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\n","stream":"stderr","time":"2021-03-11T16:50:08.6954776Z"}
{"log":"WARNING: An illegal reflective access operation has occurred\n","stream":"stderr","time":"2021-03-11T16:50:10.0139223Z"}
{"log":"WARNING: Illegal reflective access by com.headius.backport9.modules.Modules (file:/usr/share/logstash/logstash-core/lib/jars/jruby-complete-9.2.7.0.jar) to field java.io.FileDescriptor.fd\n","stream":"stderr","time":"2021-03-11T16:50:10.0139696Z"}
{"log":"WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.Modules\n","stream":"stderr","time":"2021-03-11T16:50:10.0139757Z"}
{"log":"WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","stream":"stderr","time":"2021-03-11T16:50:10.0139788Z"}
{"log":"WARNING: All illegal access operations will be denied in a future release\n","stream":"stderr","time":"2021-03-11T16:50:10.0139814Z"}
{"log":"Thread.exclusive is deprecated, use Thread::Mutex\n","stream":"stderr","time":"2021-03-11T16:50:21.9472113Z"}
{"log":"Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties\n","stream":"stdout","time":"2021-03-11T16:50:24.4641916Z"}
{"log":"[2021-03-11T16:50:24,984][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=\u003e\"7.3.2\"}\n","stream":"stdout","time":"2021-03-11T16:50:24.9873291Z"}
{"log":"[2021-03-11T16:50:25,474][WARN ][logstash.monitoringextension.pipelineregisterhook] xpack.monitoring.enabled has not been defined, but found elasticsearch configuration. Please explicitly set `xpack.monitoring.enabled: true` in logstash.yml\n","stream":"stdout","time":"2021-03-11T16:50:25.4745294Z"}
{"log":"[2021-03-11T16:50:26,104][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:50:26.1053178Z"}
{"log":"[2021-03-11T16:50:26,238][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:50:26.239147Z"}
{"log":"[2021-03-11T16:50:26,293][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:50:26.294287Z"}
{"log":"[2021-03-11T16:50:26,296][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:50:26.2974695Z"}
{"log":"[2021-03-11T16:50:26,405][INFO ][logstash.monitoring.internalpipelinesource] Monitoring License OK\n","stream":"stdout","time":"2021-03-11T16:50:26.4054168Z"}
{"log":"[2021-03-11T16:50:26,406][INFO ][logstash.monitoring.internalpipelinesource] Validated license for monitoring. Enabling monitoring pipeline.\n","stream":"stdout","time":"2021-03-11T16:50:26.4063459Z"}
{"log":"[2021-03-11T16:50:27,155][INFO ][org.reflections.Reflections] Reflections took 32 ms to scan 1 urls, producing 19 keys and 39 values \n","stream":"stdout","time":"2021-03-11T16:50:27.1561451Z"}
{"log":"[2021-03-11T16:50:28,329][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://172.20.0.3:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:50:28.3300712Z"}
{"log":"[2021-03-11T16:50:28,340][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://172.20.0.3:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:50:28.3417799Z"}
{"log":"[2021-03-11T16:50:28,347][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:50:28.3479874Z"}
{"log":"[2021-03-11T16:50:28,348][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:50:28.3485736Z"}
{"log":"[2021-03-11T16:50:28,357][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"//172.20.0.3:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:50:28.3582424Z"}
{"log":"[2021-03-11T16:50:28,396][INFO ][logstash.outputs.elasticsearch] Using default mapping template\n","stream":"stdout","time":"2021-03-11T16:50:28.3966267Z"}
{"log":"[2021-03-11T16:50:28,443][WARN ][org.logstash.instrument.metrics.gauge.LazyDelegatingGauge] A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been create for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.\n","stream":"stdout","time":"2021-03-11T16:50:28.4440994Z"}
{"log":"[2021-03-11T16:50:28,448][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e16, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2000, :thread=\u003e\"#\u003cThread:0x6c7f0be0 run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:50:28.448991Z"}
{"log":"[2021-03-11T16:50:28,448][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=\u003e{\"index_patterns\"=\u003e\"logstash-*\", \"version\"=\u003e60001, \"settings\"=\u003e{\"index.refresh_interval\"=\u003e\"5s\", \"number_of_shards\"=\u003e1}, \"mappings\"=\u003e{\"dynamic_templates\"=\u003e[{\"message_field\"=\u003e{\"path_match\"=\u003e\"message\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse}}}, {\"string_fields\"=\u003e{\"match\"=\u003e\"*\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse, \"fields\"=\u003e{\"keyword\"=\u003e{\"type\"=\u003e\"keyword\", \"ignore_above\"=\u003e256}}}}}], \"properties\"=\u003e{\"@timestamp\"=\u003e{\"type\"=\u003e\"date\"}, \"@version\"=\u003e{\"type\"=\u003e\"keyword\"}, \"geoip\"=\u003e{\"dynamic\"=\u003etrue, \"properties\"=\u003e{\"ip\"=\u003e{\"type\"=\u003e\"ip\"}, \"location\"=\u003e{\"type\"=\u003e\"geo_point\"}, \"latitude\"=\u003e{\"type\"=\u003e\"half_float\"}, \"longitude\"=\u003e{\"type\"=\u003e\"half_float\"}}}}}}}\n","stream":"stdout","time":"2021-03-11T16:50:28.4491839Z"}
{"log":"[2021-03-11T16:50:28,795][INFO ][logstash.inputs.file     ] No sincedb_path set, generating one based on the \"path\" setting {:sincedb_path=\u003e\"/usr/share/logstash/data/plugins/inputs/file/.sincedb_b7a3bb4495f9939e1fe659452575c1f2\", :path=\u003e[\"/home/logs/testLogJson.json\"]}\n","stream":"stdout","time":"2021-03-11T16:50:28.7955721Z"}
{"log":"[2021-03-11T16:50:28,822][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:50:28.8230401Z"}
{"log":"[2021-03-11T16:50:28,884][INFO ][filewatch.observingtail  ] START, creating Discoverer, Watch with file and sincedb collections\n","stream":"stdout","time":"2021-03-11T16:50:28.8855572Z"}
{"log":"[2021-03-11T16:50:28,893][INFO ][logstash.agent           ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:50:28.8938646Z"}
{"log":"[2021-03-11T16:50:29,296][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting \"document_type\" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=\u003e\"document_type\", :plugin=\u003e\u003cLogStash::Outputs::ElasticSearch bulk_path=\u003e\"/_monitoring/bulk?system_id=logstash\u0026system_api_version=7\u0026interval=1s\", hosts=\u003e[http://elasticsearch:9200], sniffing=\u003efalse, manage_template=\u003efalse, id=\u003e\"7d7dfa0f023f65240aeb31ebb353da5a42dc782979a2bd7e26e28b7cbd509bb3\", document_type=\u003e\"%{[@metadata][document_type]}\", enable_metric=\u003etrue, codec=\u003e\u003cLogStash::Codecs::Plain id=\u003e\"plain_34fea1b7-a7f4-441f-a27b-7c472b54685f\", enable_metric=\u003etrue, charset=\u003e\"UTF-8\"\u003e, workers=\u003e1, template_name=\u003e\"logstash\", template_overwrite=\u003efalse, doc_as_upsert=\u003efalse, script_type=\u003e\"inline\", script_lang=\u003e\"painless\", script_var_name=\u003e\"event\", scripted_upsert=\u003efalse, retry_initial_interval=\u003e2, retry_max_interval=\u003e64, retry_on_conflict=\u003e1, ilm_enabled=\u003e\"auto\", ilm_rollover_alias=\u003e\"logstash\", ilm_pattern=\u003e\"{now/d}-000001\", ilm_policy=\u003e\"logstash-policy\", action=\u003e\"index\", ssl_certificate_verification=\u003etrue, sniffing_delay=\u003e5, timeout=\u003e60, pool_max=\u003e1000, pool_max_per_route=\u003e100, resurrect_delay=\u003e5, validate_after_inactivity=\u003e10000, http_compression=\u003efalse\u003e}\n","stream":"stdout","time":"2021-03-11T16:50:29.29999Z"}
{"log":"[2021-03-11T16:50:29,326][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:50:29.3266763Z"}
{"log":"[2021-03-11T16:50:29,330][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:50:29.3306377Z"}
{"log":"[2021-03-11T16:50:29,334][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:50:29.3349238Z"}
{"log":"[2021-03-11T16:50:29,334][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:50:29.335363Z"}
{"log":"[2021-03-11T16:50:29,337][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"http://elasticsearch:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:50:29.3379065Z"}
{"log":"[2021-03-11T16:50:29,344][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\".monitoring-logstash\", \"pipeline.workers\"=\u003e1, \"pipeline.batch.size\"=\u003e2, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2, :thread=\u003e\"#\u003cThread:0x2ba3bec2 run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:50:29.3454187Z"}
{"log":"[2021-03-11T16:50:29,364][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:50:29.3653287Z"}
{"log":"[2021-03-11T16:50:29,376][INFO ][logstash.agent           ] Pipelines running {:count=\u003e2, :running_pipelines=\u003e[:main, :\".monitoring-logstash\"], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:50:29.3778579Z"}
{"log":"[2021-03-11T16:50:29,643][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=\u003e9600}\n","stream":"stdout","time":"2021-03-11T16:50:29.6436831Z"}
{"log":"[2021-03-11T16:50:51,468][WARN ][logstash.runner          ] SIGTERM received. Shutting down.\n","stream":"stdout","time":"2021-03-11T16:50:51.4687385Z"}
{"log":"[2021-03-11T16:50:51,529][INFO ][filewatch.observingtail  ] QUIT - closing all files and shutting down.\n","stream":"stdout","time":"2021-03-11T16:50:51.5296578Z"}
{"log":"[2021-03-11T16:50:52,439][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:50:52.439506Z"}
{"log":"[2021-03-11T16:50:52,496][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:50:52.4965539Z"}
{"log":"[2021-03-11T16:50:53,392][INFO ][logstash.runner          ] Logstash shut down.\n","stream":"stdout","time":"2021-03-11T16:50:53.3931538Z"}
{"log":"OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\n","stream":"stderr","time":"2021-03-11T16:50:56.7886435Z"}
{"log":"WARNING: An illegal reflective access operation has occurred\n","stream":"stderr","time":"2021-03-11T16:50:58.0206413Z"}
{"log":"WARNING: Illegal reflective access by com.headius.backport9.modules.Modules (file:/usr/share/logstash/logstash-core/lib/jars/jruby-complete-9.2.7.0.jar) to field java.io.FileDescriptor.fd\n","stream":"stderr","time":"2021-03-11T16:50:58.0206716Z"}
{"log":"WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.Modules\n","stream":"stderr","time":"2021-03-11T16:50:58.0206745Z"}
{"log":"WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","stream":"stderr","time":"2021-03-11T16:50:58.0206768Z"}
{"log":"WARNING: All illegal access operations will be denied in a future release\n","stream":"stderr","time":"2021-03-11T16:50:58.0206788Z"}
{"log":"Thread.exclusive is deprecated, use Thread::Mutex\n","stream":"stderr","time":"2021-03-11T16:51:08.4874969Z"}
{"log":"Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties\n","stream":"stdout","time":"2021-03-11T16:51:10.7863012Z"}
{"log":"[2021-03-11T16:51:11,171][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=\u003e\"7.3.2\"}\n","stream":"stdout","time":"2021-03-11T16:51:11.1735514Z"}
{"log":"[2021-03-11T16:51:11,600][WARN ][logstash.monitoringextension.pipelineregisterhook] xpack.monitoring.enabled has not been defined, but found elasticsearch configuration. Please explicitly set `xpack.monitoring.enabled: true` in logstash.yml\n","stream":"stdout","time":"2021-03-11T16:51:11.6008613Z"}
{"log":"[2021-03-11T16:51:12,244][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:51:12.245324Z"}
{"log":"[2021-03-11T16:51:12,417][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:51:12.4176176Z"}
{"log":"[2021-03-11T16:51:12,472][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:51:12.4729864Z"}
{"log":"[2021-03-11T16:51:12,475][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:51:12.4758426Z"}
{"log":"[2021-03-11T16:51:12,578][INFO ][logstash.monitoring.internalpipelinesource] Monitoring License OK\n","stream":"stdout","time":"2021-03-11T16:51:12.5791094Z"}
{"log":"[2021-03-11T16:51:12,579][INFO ][logstash.monitoring.internalpipelinesource] Validated license for monitoring. Enabling monitoring pipeline.\n","stream":"stdout","time":"2021-03-11T16:51:12.5800035Z"}
{"log":"[2021-03-11T16:51:13,274][INFO ][org.reflections.Reflections] Reflections took 27 ms to scan 1 urls, producing 19 keys and 39 values \n","stream":"stdout","time":"2021-03-11T16:51:13.2756784Z"}
{"log":"[2021-03-11T16:51:14,273][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://172.20.0.3:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:51:14.2745708Z"}
{"log":"[2021-03-11T16:51:14,283][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://172.20.0.3:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:51:14.2840418Z"}
{"log":"[2021-03-11T16:51:14,289][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:51:14.2895664Z"}
{"log":"[2021-03-11T16:51:14,289][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:51:14.2898905Z"}
{"log":"[2021-03-11T16:51:14,299][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"//172.20.0.3:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:51:14.2995593Z"}
{"log":"[2021-03-11T16:51:14,328][INFO ][logstash.outputs.elasticsearch] Using default mapping template\n","stream":"stdout","time":"2021-03-11T16:51:14.3293661Z"}
{"log":"[2021-03-11T16:51:14,368][WARN ][org.logstash.instrument.metrics.gauge.LazyDelegatingGauge] A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been create for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.\n","stream":"stdout","time":"2021-03-11T16:51:14.3684933Z"}
{"log":"[2021-03-11T16:51:14,372][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e16, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2000, :thread=\u003e\"#\u003cThread:0x39dd636b run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:51:14.3727536Z"}
{"log":"[2021-03-11T16:51:14,373][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=\u003e{\"index_patterns\"=\u003e\"logstash-*\", \"version\"=\u003e60001, \"settings\"=\u003e{\"index.refresh_interval\"=\u003e\"5s\", \"number_of_shards\"=\u003e1}, \"mappings\"=\u003e{\"dynamic_templates\"=\u003e[{\"message_field\"=\u003e{\"path_match\"=\u003e\"message\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse}}}, {\"string_fields\"=\u003e{\"match\"=\u003e\"*\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse, \"fields\"=\u003e{\"keyword\"=\u003e{\"type\"=\u003e\"keyword\", \"ignore_above\"=\u003e256}}}}}], \"properties\"=\u003e{\"@timestamp\"=\u003e{\"type\"=\u003e\"date\"}, \"@version\"=\u003e{\"type\"=\u003e\"keyword\"}, \"geoip\"=\u003e{\"dynamic\"=\u003etrue, \"properties\"=\u003e{\"ip\"=\u003e{\"type\"=\u003e\"ip\"}, \"location\"=\u003e{\"type\"=\u003e\"geo_point\"}, \"latitude\"=\u003e{\"type\"=\u003e\"half_float\"}, \"longitude\"=\u003e{\"type\"=\u003e\"half_float\"}}}}}}}\n","stream":"stdout","time":"2021-03-11T16:51:14.3741898Z"}
{"log":"[2021-03-11T16:51:14,626][INFO ][logstash.inputs.file     ] No sincedb_path set, generating one based on the \"path\" setting {:sincedb_path=\u003e\"/usr/share/logstash/data/plugins/inputs/file/.sincedb_b7a3bb4495f9939e1fe659452575c1f2\", :path=\u003e[\"/home/logs/testLogJson.json\"]}\n","stream":"stdout","time":"2021-03-11T16:51:14.6271905Z"}
{"log":"[2021-03-11T16:51:14,651][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:51:14.652292Z"}
{"log":"[2021-03-11T16:51:14,700][INFO ][filewatch.observingtail  ] START, creating Discoverer, Watch with file and sincedb collections\n","stream":"stdout","time":"2021-03-11T16:51:14.7016167Z"}
{"log":"[2021-03-11T16:51:14,717][INFO ][logstash.agent           ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:51:14.7176983Z"}
{"log":"[2021-03-11T16:51:15,110][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting \"document_type\" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=\u003e\"document_type\", :plugin=\u003e\u003cLogStash::Outputs::ElasticSearch bulk_path=\u003e\"/_monitoring/bulk?system_id=logstash\u0026system_api_version=7\u0026interval=1s\", hosts=\u003e[http://elasticsearch:9200], sniffing=\u003efalse, manage_template=\u003efalse, id=\u003e\"7d7dfa0f023f65240aeb31ebb353da5a42dc782979a2bd7e26e28b7cbd509bb3\", document_type=\u003e\"%{[@metadata][document_type]}\", enable_metric=\u003etrue, codec=\u003e\u003cLogStash::Codecs::Plain id=\u003e\"plain_b3a70928-10ab-4b7a-86d5-797aed25e5f1\", enable_metric=\u003etrue, charset=\u003e\"UTF-8\"\u003e, workers=\u003e1, template_name=\u003e\"logstash\", template_overwrite=\u003efalse, doc_as_upsert=\u003efalse, script_type=\u003e\"inline\", script_lang=\u003e\"painless\", script_var_name=\u003e\"event\", scripted_upsert=\u003efalse, retry_initial_interval=\u003e2, retry_max_interval=\u003e64, retry_on_conflict=\u003e1, ilm_enabled=\u003e\"auto\", ilm_rollover_alias=\u003e\"logstash\", ilm_pattern=\u003e\"{now/d}-000001\", ilm_policy=\u003e\"logstash-policy\", action=\u003e\"index\", ssl_certificate_verification=\u003etrue, sniffing_delay=\u003e5, timeout=\u003e60, pool_max=\u003e1000, pool_max_per_route=\u003e100, resurrect_delay=\u003e5, validate_after_inactivity=\u003e10000, http_compression=\u003efalse\u003e}\n","stream":"stdout","time":"2021-03-11T16:51:15.1144817Z"}
{"log":"[2021-03-11T16:51:15,141][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:51:15.1421314Z"}
{"log":"[2021-03-11T16:51:15,146][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:51:15.1464417Z"}
{"log":"[2021-03-11T16:51:15,151][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:51:15.1519865Z"}
{"log":"[2021-03-11T16:51:15,152][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:51:15.1523795Z"}
{"log":"[2021-03-11T16:51:15,155][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"http://elasticsearch:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:51:15.1556487Z"}
{"log":"[2021-03-11T16:51:15,162][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\".monitoring-logstash\", \"pipeline.workers\"=\u003e1, \"pipeline.batch.size\"=\u003e2, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2, :thread=\u003e\"#\u003cThread:0x2b54fe3d run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:51:15.163414Z"}
{"log":"[2021-03-11T16:51:15,207][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:51:15.2079347Z"}
{"log":"[2021-03-11T16:51:15,223][INFO ][logstash.agent           ] Pipelines running {:count=\u003e2, :running_pipelines=\u003e[:main, :\".monitoring-logstash\"], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:51:15.2245427Z"}
{"log":"[2021-03-11T16:51:15,477][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=\u003e9600}\n","stream":"stdout","time":"2021-03-11T16:51:15.4782939Z"}
{"log":"[2021-03-11T16:53:00,198][WARN ][logstash.runner          ] SIGTERM received. Shutting down.\n","stream":"stdout","time":"2021-03-11T16:53:00.198864Z"}
{"log":"[2021-03-11T16:53:00,261][INFO ][filewatch.observingtail  ] QUIT - closing all files and shutting down.\n","stream":"stdout","time":"2021-03-11T16:53:00.2617622Z"}
{"log":"[2021-03-11T16:53:00,413][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:53:00.4153468Z"}
{"log":"[2021-03-11T16:53:00,417][INFO ][logstash.javapipeline    ] Pipeline terminated {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:53:00.418481Z"}
{"log":"[2021-03-11T16:53:01,371][INFO ][logstash.runner          ] Logstash shut down.\n","stream":"stdout","time":"2021-03-11T16:53:01.372094Z"}
{"log":"OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.\n","stream":"stderr","time":"2021-03-11T16:53:02.1591282Z"}
{"log":"WARNING: An illegal reflective access operation has occurred\n","stream":"stderr","time":"2021-03-11T16:53:03.3622276Z"}
{"log":"WARNING: Illegal reflective access by com.headius.backport9.modules.Modules (file:/usr/share/logstash/logstash-core/lib/jars/jruby-complete-9.2.7.0.jar) to field java.io.FileDescriptor.fd\n","stream":"stderr","time":"2021-03-11T16:53:03.3622678Z"}
{"log":"WARNING: Please consider reporting this to the maintainers of com.headius.backport9.modules.Modules\n","stream":"stderr","time":"2021-03-11T16:53:03.3622742Z"}
{"log":"WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","stream":"stderr","time":"2021-03-11T16:53:03.3622765Z"}
{"log":"WARNING: All illegal access operations will be denied in a future release\n","stream":"stderr","time":"2021-03-11T16:53:03.3622785Z"}
{"log":"Thread.exclusive is deprecated, use Thread::Mutex\n","stream":"stderr","time":"2021-03-11T16:53:13.3002698Z"}
{"log":"Sending Logstash logs to /usr/share/logstash/logs which is now configured via log4j2.properties\n","stream":"stdout","time":"2021-03-11T16:53:15.9381307Z"}
{"log":"[2021-03-11T16:53:16,379][INFO ][logstash.runner          ] Starting Logstash {\"logstash.version\"=\u003e\"7.3.2\"}\n","stream":"stdout","time":"2021-03-11T16:53:16.3817198Z"}
{"log":"[2021-03-11T16:53:16,812][WARN ][logstash.monitoringextension.pipelineregisterhook] xpack.monitoring.enabled has not been defined, but found elasticsearch configuration. Please explicitly set `xpack.monitoring.enabled: true` in logstash.yml\n","stream":"stdout","time":"2021-03-11T16:53:16.8135248Z"}
{"log":"[2021-03-11T16:53:17,424][INFO ][logstash.licensechecker.licensereader] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:53:17.4254265Z"}
{"log":"[2021-03-11T16:53:17,560][WARN ][logstash.licensechecker.licensereader] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:53:17.5607414Z"}
{"log":"[2021-03-11T16:53:17,601][INFO ][logstash.licensechecker.licensereader] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:53:17.6015919Z"}
{"log":"[2021-03-11T16:53:17,603][WARN ][logstash.licensechecker.licensereader] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:53:17.6039849Z"}
{"log":"[2021-03-11T16:53:17,697][INFO ][logstash.monitoring.internalpipelinesource] Monitoring License OK\n","stream":"stdout","time":"2021-03-11T16:53:17.6982762Z"}
{"log":"[2021-03-11T16:53:17,699][INFO ][logstash.monitoring.internalpipelinesource] Validated license for monitoring. Enabling monitoring pipeline.\n","stream":"stdout","time":"2021-03-11T16:53:17.6997713Z"}
{"log":"[2021-03-11T16:53:18,326][INFO ][org.reflections.Reflections] Reflections took 25 ms to scan 1 urls, producing 19 keys and 39 values \n","stream":"stdout","time":"2021-03-11T16:53:18.3277418Z"}
{"log":"[2021-03-11T16:53:19,305][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://172.20.0.3:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:53:19.3061318Z"}
{"log":"[2021-03-11T16:53:19,313][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://172.20.0.3:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:53:19.3143584Z"}
{"log":"[2021-03-11T16:53:19,318][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:53:19.319182Z"}
{"log":"[2021-03-11T16:53:19,319][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:53:19.3195023Z"}
{"log":"[2021-03-11T16:53:19,328][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"//172.20.0.3:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:53:19.3290062Z"}
{"log":"[2021-03-11T16:53:19,356][INFO ][logstash.outputs.elasticsearch] Using default mapping template\n","stream":"stdout","time":"2021-03-11T16:53:19.3571377Z"}
{"log":"[2021-03-11T16:53:19,393][WARN ][org.logstash.instrument.metrics.gauge.LazyDelegatingGauge] A gauge metric of an unknown type (org.jruby.specialized.RubyArrayOneObject) has been create for key: cluster_uuids. This may result in invalid serialization.  It is recommended to log an issue to the responsible developer/development team.\n","stream":"stdout","time":"2021-03-11T16:53:19.3937924Z"}
{"log":"[2021-03-11T16:53:19,395][INFO ][logstash.outputs.elasticsearch] Attempting to install template {:manage_template=\u003e{\"index_patterns\"=\u003e\"logstash-*\", \"version\"=\u003e60001, \"settings\"=\u003e{\"index.refresh_interval\"=\u003e\"5s\", \"number_of_shards\"=\u003e1}, \"mappings\"=\u003e{\"dynamic_templates\"=\u003e[{\"message_field\"=\u003e{\"path_match\"=\u003e\"message\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse}}}, {\"string_fields\"=\u003e{\"match\"=\u003e\"*\", \"match_mapping_type\"=\u003e\"string\", \"mapping\"=\u003e{\"type\"=\u003e\"text\", \"norms\"=\u003efalse, \"fields\"=\u003e{\"keyword\"=\u003e{\"type\"=\u003e\"keyword\", \"ignore_above\"=\u003e256}}}}}], \"properties\"=\u003e{\"@timestamp\"=\u003e{\"type\"=\u003e\"date\"}, \"@version\"=\u003e{\"type\"=\u003e\"keyword\"}, \"geoip\"=\u003e{\"dynamic\"=\u003etrue, \"properties\"=\u003e{\"ip\"=\u003e{\"type\"=\u003e\"ip\"}, \"location\"=\u003e{\"type\"=\u003e\"geo_point\"}, \"latitude\"=\u003e{\"type\"=\u003e\"half_float\"}, \"longitude\"=\u003e{\"type\"=\u003e\"half_float\"}}}}}}}\n","stream":"stdout","time":"2021-03-11T16:53:19.3964595Z"}
{"log":"[2021-03-11T16:53:19,396][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\"main\", \"pipeline.workers\"=\u003e16, \"pipeline.batch.size\"=\u003e125, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2000, :thread=\u003e\"#\u003cThread:0x24df8f0c run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:53:19.3965251Z"}
{"log":"[2021-03-11T16:53:19,664][INFO ][logstash.inputs.file     ] No sincedb_path set, generating one based on the \"path\" setting {:sincedb_path=\u003e\"/usr/share/logstash/data/plugins/inputs/file/.sincedb_b7a3bb4495f9939e1fe659452575c1f2\", :path=\u003e[\"/home/logs/testLogJson.json\"]}\n","stream":"stdout","time":"2021-03-11T16:53:19.6649957Z"}
{"log":"[2021-03-11T16:53:19,688][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\"main\"}\n","stream":"stdout","time":"2021-03-11T16:53:19.6890319Z"}
{"log":"[2021-03-11T16:53:19,727][INFO ][filewatch.observingtail  ] START, creating Discoverer, Watch with file and sincedb collections\n","stream":"stdout","time":"2021-03-11T16:53:19.7278855Z"}
{"log":"[2021-03-11T16:53:19,743][INFO ][logstash.agent           ] Pipelines running {:count=\u003e1, :running_pipelines=\u003e[:main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:53:19.7438752Z"}
{"log":"[2021-03-11T16:53:20,117][WARN ][logstash.outputs.elasticsearch] You are using a deprecated config setting \"document_type\" set in elasticsearch. Deprecated settings will continue to work, but are scheduled for removal from logstash in the future. Document types are being deprecated in Elasticsearch 6.0, and removed entirely in 7.0. You should avoid this feature If you have any questions about this, please visit the #logstash channel on freenode irc. {:name=\u003e\"document_type\", :plugin=\u003e\u003cLogStash::Outputs::ElasticSearch bulk_path=\u003e\"/_monitoring/bulk?system_id=logstash\u0026system_api_version=7\u0026interval=1s\", hosts=\u003e[http://elasticsearch:9200], sniffing=\u003efalse, manage_template=\u003efalse, id=\u003e\"7d7dfa0f023f65240aeb31ebb353da5a42dc782979a2bd7e26e28b7cbd509bb3\", document_type=\u003e\"%{[@metadata][document_type]}\", enable_metric=\u003etrue, codec=\u003e\u003cLogStash::Codecs::Plain id=\u003e\"plain_25b5c4c7-5a13-430c-b1b2-39ed051fa550\", enable_metric=\u003etrue, charset=\u003e\"UTF-8\"\u003e, workers=\u003e1, template_name=\u003e\"logstash\", template_overwrite=\u003efalse, doc_as_upsert=\u003efalse, script_type=\u003e\"inline\", script_lang=\u003e\"painless\", script_var_name=\u003e\"event\", scripted_upsert=\u003efalse, retry_initial_interval=\u003e2, retry_max_interval=\u003e64, retry_on_conflict=\u003e1, ilm_enabled=\u003e\"auto\", ilm_rollover_alias=\u003e\"logstash\", ilm_pattern=\u003e\"{now/d}-000001\", ilm_policy=\u003e\"logstash-policy\", action=\u003e\"index\", ssl_certificate_verification=\u003etrue, sniffing_delay=\u003e5, timeout=\u003e60, pool_max=\u003e1000, pool_max_per_route=\u003e100, resurrect_delay=\u003e5, validate_after_inactivity=\u003e10000, http_compression=\u003efalse\u003e}\n","stream":"stdout","time":"2021-03-11T16:53:20.1207243Z"}
{"log":"[2021-03-11T16:53:20,141][INFO ][logstash.outputs.elasticsearch] Elasticsearch pool URLs updated {:changes=\u003e{:removed=\u003e[], :added=\u003e[http://elasticsearch:9200/]}}\n","stream":"stdout","time":"2021-03-11T16:53:20.1424165Z"}
{"log":"[2021-03-11T16:53:20,146][WARN ][logstash.outputs.elasticsearch] Restored connection to ES instance {:url=\u003e\"http://elasticsearch:9200/\"}\n","stream":"stdout","time":"2021-03-11T16:53:20.1467438Z"}
{"log":"[2021-03-11T16:53:20,151][INFO ][logstash.outputs.elasticsearch] ES Output version determined {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:53:20.1520091Z"}
{"log":"[2021-03-11T16:53:20,152][WARN ][logstash.outputs.elasticsearch] Detected a 6.x and above cluster: the `type` event field won't be used to determine the document _type {:es_version=\u003e7}\n","stream":"stdout","time":"2021-03-11T16:53:20.1528632Z"}
{"log":"[2021-03-11T16:53:20,155][INFO ][logstash.outputs.elasticsearch] New Elasticsearch output {:class=\u003e\"LogStash::Outputs::ElasticSearch\", :hosts=\u003e[\"http://elasticsearch:9200\"]}\n","stream":"stdout","time":"2021-03-11T16:53:20.1556543Z"}
{"log":"[2021-03-11T16:53:20,167][INFO ][logstash.javapipeline    ] Starting pipeline {:pipeline_id=\u003e\".monitoring-logstash\", \"pipeline.workers\"=\u003e1, \"pipeline.batch.size\"=\u003e2, \"pipeline.batch.delay\"=\u003e50, \"pipeline.max_inflight\"=\u003e2, :thread=\u003e\"#\u003cThread:0x6f12a2db run\u003e\"}\n","stream":"stdout","time":"2021-03-11T16:53:20.1676847Z"}
{"log":"[2021-03-11T16:53:20,186][INFO ][logstash.javapipeline    ] Pipeline started {\"pipeline.id\"=\u003e\".monitoring-logstash\"}\n","stream":"stdout","time":"2021-03-11T16:53:20.1865999Z"}
{"log":"[2021-03-11T16:53:20,198][INFO ][logstash.agent           ] Pipelines running {:count=\u003e2, :running_pipelines=\u003e[:\".monitoring-logstash\", :main], :non_running_pipelines=\u003e[]}\n","stream":"stdout","time":"2021-03-11T16:53:20.1998164Z"}
{"log":"[2021-03-11T16:53:20,418][INFO ][logstash.agent           ] Successfully started Logstash API endpoint {:port=\u003e9600}\n","stream":"stdout","time":"2021-03-11T16:53:20.4190025Z"}
